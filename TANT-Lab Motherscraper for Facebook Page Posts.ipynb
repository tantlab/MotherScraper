{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Description: \n",
    "    #- The script automatically generates a folder for harvest jsons. \n",
    "    #- The script generates a json called missing where all the skipped IDs are entered no matter where in the script things went wrong.\n",
    "    \n",
    "#Remember to:  \n",
    "    #- Change the name of the seedlist. Dont call it .json. It will be appended. The seedlist must be in the rootfolder\n",
    "    #- Adjust the start and endtime, and limits\n",
    "    #- Insert email address for notifications (remember to look in the spamfolder)\n",
    "\n",
    "#prerequisites:\n",
    "    #- Seedlist must be in a flat .json structure as a list [\"FB_ID_1\",\" FB_ID_2\", etc]\n",
    "\n",
    "import sys\n",
    "import smtplib\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import facebook\n",
    "except:\n",
    "    print('Facebook-sdk not installed. Installing...')\n",
    "    install_facebook()\n",
    "\n",
    "import facebook\n",
    "\n",
    "############Insert the name of your seedlist without .json############\n",
    "\n",
    "seedlist_name='SeedlistName' \n",
    "\n",
    "############Insert appID and secret############\n",
    "\n",
    "appID= 'AppID' \n",
    "appsecret='AppSecret'\n",
    "\n",
    "\n",
    "############Adjust limits############\n",
    "\n",
    "postlimit_start=20 #set to 80\n",
    "reactionlimit='600' #max 1000\n",
    "commentlimit= '40' #max 100\n",
    "\n",
    "############Adjust start and end dates###########\n",
    "startdate='01-01-2012'\n",
    "enddate='31-12-2013'\n",
    "\n",
    "############Mail setup###########\n",
    "mail_address_1=\"\"\n",
    "mail_address_2=\"\"\n",
    "mails = [mail_address_1, mail_address_2]\n",
    "gmail_sender = ''\n",
    "gmail_passwd = ''\n",
    "email_notifications=1 #1 for notifications and 0 for none\n",
    "\n",
    "\n",
    "\n",
    "############Other initial definitions##########\n",
    "seedlist=seedlist_name+'.json'\n",
    "sleep_time=0.1\n",
    "graph = facebook.GraphAPI(access_token=appID+'|'+appsecret, version='2.7')\n",
    "start_time_total=time.time()\n",
    "\n",
    "\n",
    "##########Create harvest folder##########\n",
    "if not os.path.exists(seedlist_name):\n",
    "    os.makedirs(seedlist_name)\n",
    "    \n",
    "##########Create json for skipped IDs#############    \n",
    "\n",
    "missing='missing_'+seedlist_name+'_'+startdate+'_'+enddate+'.json'\n",
    "\n",
    "if not os.path.exists(missing):\n",
    "    with open(missing, 'w') as outfile:\n",
    "        json.dump([], outfile, ensure_ascii=False)\n",
    "\n",
    "        \n",
    "def send_mail(TO, SUBJECT, TEXT):\n",
    "\n",
    "\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(gmail_sender, gmail_passwd)\n",
    "\n",
    "    BODY = '\\r\\n'.join(['To: %s' % TO,\n",
    "                        'From: %s' % gmail_sender,\n",
    "                        'Subject: %s' % SUBJECT,\n",
    "                        '', TEXT])\n",
    "\n",
    "    try:\n",
    "        server.sendmail(gmail_sender, [TO], BODY)\n",
    "        print('email sent to '+TO)\n",
    "    except:\n",
    "        print ('error sending mail')\n",
    "\n",
    "    server.quit()        \n",
    "\n",
    "def install_facebook():\n",
    "    !{sys.executable} -m pip install facebook-sdk\n",
    "    print('Facebook-sdk installed. Importing...')\n",
    "    import facebook\n",
    "    print('Facebook imported')\n",
    "        \n",
    "def skip_id(missing_data):\n",
    "    with open(missing) as f:\n",
    "        data=json.load(f)\n",
    "    data.append(missing_data)\n",
    "    with open(missing, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def paging_postreactions(): #comment_reactions or post_reactions or commentcomment_reactions\n",
    "    connection_r=1\n",
    "    reactionpaging_token=reactions['paging']\n",
    "    while 'next' in reactionpaging_token and connection_r:\n",
    "        reactionpaging_token=reactionpaging_token['next']\n",
    "        reactionpaging_token = reactionpaging_token.split('/')\n",
    "        reactionpaging_token = '/' + reactionpaging_token[4] + '/' + reactionpaging_token[5]\n",
    "        reactionpaging_data=graph.get_object(id=reactionpaging_token)\n",
    "        try:\n",
    "            reactionpaging_data=graph.get_object(id=reactionpaging_token)\n",
    "            for reaction in reactionpaging_data['data']:\n",
    "                comment_reactions.append(reaction)\n",
    "            reactionpaging_token=reactionpaging_data['paging']\n",
    "            time.sleep(sleep_time)\n",
    "        except:\n",
    "            print('Problems with comments comments reactions.. Skipping ID')\n",
    "            connection_r=0\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "def paging_commentreactions(): #comment_reactions or post_reactions or commentcomment_reactions\n",
    "    connection_cr=1\n",
    "    reactionpaging_token=reactions['paging']\n",
    "    while 'next' in reactionpaging_token and connection_cr:\n",
    "        reactionpaging_token=reactionpaging_token['next']\n",
    "        reactionpaging_token = reactionpaging_token.split('/')\n",
    "        reactionpaging_token = '/' + reactionpaging_token[4] + '/' + reactionpaging_token[5]\n",
    "        try:\n",
    "            reactionpaging_data=graph.get_object(id=reactionpaging_token)\n",
    "            for reaction in reactionpaging_data['data']:\n",
    "                comment_reactions.append(reaction)\n",
    "            reactionpaging_token=reactionpaging_data['paging']\n",
    "            time.sleep(sleep_time)\n",
    "        except:\n",
    "            print('Problems with comments reactions.. Skipping ID')\n",
    "            connection_cr=0\n",
    "            continue\n",
    "\n",
    "def paging_commentcommentreactions(): #comment_reactions or post_reactions or commentcomment_reactions\n",
    "    connection_ccr=1\n",
    "    reactionpaging_token=reactions['paging']\n",
    "    print(\"paging comment comment reaction\")\n",
    "    while 'next' in reactionpaging_token and connection_ccr:\n",
    "        reactionpaging_token=reactionpaging_token['next']\n",
    "        reactionpaging_token = reactionpaging_token.split('/')\n",
    "        reactionpaging_token = '/' + reactionpaging_token[4] + '/' + reactionpaging_token[5]\n",
    "        try:\n",
    "            reactionpaging_data=graph.get_object(id=reactionpaging_token)\n",
    "            for reaction in reactionpaging_data['data']:\n",
    "                commentcomment_reactions.append(reaction)\n",
    "            reactionpaging_token=reactionpaging_data['paging']\n",
    "            time.sleep(sleep_time)\n",
    "        except:\n",
    "            print('Problems with comments comments reactions.. Skipping ID')\n",
    "            connection_ccr=0\n",
    "            continue\n",
    "\n",
    "\n",
    "def paging_commentcomment(): \n",
    "    connection_commentcomment=1\n",
    "    commentcommentpaging_token=commentcomments['paging']\n",
    "    while 'next' in commentcommentpaging_token and connection_commentcomment:\n",
    "        commentcommentpaging_token=commentcommentpaging_token['next']\n",
    "        commentcommentpaging_token = commentcommentpaging_token.split('/')\n",
    "        commentcommentpaging_token = '/' + commentcommentpaging_token[4] + '/' + commentcommentpaging_token[5]\n",
    "        try:\n",
    "            \n",
    "            commentcommentpaging_data=graph.get_object(id=commentcommentpaging_token)\n",
    "            for commentcomment in commentcommentpaging_data['data']:\n",
    "                commentcomment_time = commentcomment['created_time']\n",
    "                commentcomment_id = commentcomment['id']\n",
    "                commentcomment_author = commentcomment['from']\n",
    "                if 'message' in commentcomment:\n",
    "                    commentcomment_message = commentcomment['message']\n",
    "                else:\n",
    "                    commentcomment_message = ''\n",
    "\n",
    "                #iteratae over commentcomment reactions\n",
    "                commentcomment_reactions=[]\n",
    "                if 'reactions' in commentcomment:\n",
    "                    reactions = commentcomment['reactions']\n",
    "                    for reaction in reactions['data']:\n",
    "                        commentcomment_reactions.append(reaction)\n",
    "                    paging_commentcommentreactions()\n",
    "\n",
    "\n",
    "                COMMENTCOMMENTDIC = {'commentcomment_time':commentcomment_time,'commentcomment_id':commentcomment_id,'commentcomment_message':commentcomment_message,'commentcomment_author':commentcomment_author,'commentcomment_reactions':commentcomment_reactions}\n",
    "                commentcomments_data.append(COMMENTCOMMENTDIC)\n",
    "            time.sleep(sleep_time)\n",
    "            commentcommentpaging_token=commentcommentpaging_data['paging']\n",
    "        except:\n",
    "            print('Problems with comment paging.. Skipping ID')\n",
    "            connection_commentcomment=0\n",
    "            continue\n",
    "       \n",
    "\n",
    "            \n",
    "def paging_comment(): #commentcomment or comment\n",
    "    connection_comment=1\n",
    "    y=1\n",
    "    commentpaging_token=comments['paging']\n",
    "    while 'next' in commentpaging_token and y<11 and connection_comment:\n",
    "        commentpaging_token=commentpaging_token['next']\n",
    "        commentpaging_token = commentpaging_token.split('/')\n",
    "        commentpaging_token = '/' + commentpaging_token[4] + '/' + commentpaging_token[5]\n",
    "        try:\n",
    "            \n",
    "            commentpaging_data=graph.get_object(id=commentpaging_token)\n",
    "            for comment in commentpaging_data['data']:\n",
    "\n",
    "                comment_time = comment['created_time']\n",
    "                comment_id = comment['id']\n",
    "                comment_author = comment['from']\n",
    "                if 'message' in comment:\n",
    "                    comment_message = comment['message']\n",
    "                else:\n",
    "                    comment_message = ''\n",
    "                comment_reactions=[]\n",
    "                if 'reactions' in comment:\n",
    "                        reactions = comment['reactions'] \n",
    "                        for reaction in reactions['data']:\n",
    "                            comment_reactions.append(reaction)\n",
    "                        paging_commentreactions()\n",
    "                commentcomments_data=[]\n",
    "                if 'comment' in comment: \n",
    "                    commentcomment=comment['comments']\n",
    "                    print(commentcomment)\n",
    "\n",
    "                    paging_commentcomment()\n",
    "                COMMENTDIC = {'comment_time':comment_time,'comment_id':comment_id,'comment_message':comment_message,'comment_author':comment_author,'comment_reactions':comment_reactions,'commentcomments':commentcomments_data}\n",
    "                comments_data.append(COMMENTDIC)\n",
    "            time.sleep(sleep_time)\n",
    "            commentpaging_token=commentpaging_data['paging']\n",
    "            y=y+1\n",
    "        except:\n",
    "            print('Problems with comment paging.. Skipping ID')\n",
    "            connection_comment=0\n",
    "            continue\n",
    "\n",
    "\n",
    "x=0\n",
    "data = json.load(open(seedlist))\n",
    "data=set(data)\n",
    "data=list(data)\n",
    "all_FB_ID=len(data)\n",
    "now = time.strftime(\"%H:%M\", time.localtime(time.time()))\n",
    "if all_FB_ID>60:\n",
    "    estimated_duration=str(round((all_FB_ID/60)/3,0))+' hours' \n",
    "else:\n",
    "    estimated_duration=str(round((all_FB_ID/3),0))+' minutes'\n",
    "    \n",
    "if email_notifications:\n",
    "    for mail in mails:\n",
    "        send_mail(mail, \"Motherscraper started \"+str(now), \"Motherscraper started scraping from: \"+seedlist+\". Estimated duration: \"+estimated_duration)\n",
    "else:\n",
    "    print('Email not send')\n",
    "try:\n",
    "    while x<all_FB_ID:\n",
    "       # data = json.load(open(seedlist))\n",
    "        start_time=time.time()\n",
    "        FB_ID=data[x]\n",
    "        print('Scraping '+FB_ID+' page '+str(x+1)+' of '+ str(all_FB_ID))\n",
    "        postlimit=postlimit_start\n",
    "\n",
    "        filepath=seedlist_name+'/'+FB_ID+'_'+startdate+'_to_'+enddate+'.json'\n",
    "        with open(filepath, 'w') as outfile:\n",
    "            json.dump([], outfile, ensure_ascii=False)\n",
    "\n",
    "        post_count=0\n",
    "        try: \n",
    "            print('Fetching data')\n",
    "            feed_data = graph.get_object(FB_ID+'/feed?fields=from,created_time,link,picture,message,story,scheduled_publish_time,reactions.limit('+reactionlimit+'){id,type},comments.limit('+commentlimit+'){comments.limit('+commentlimit+'){from,created_time,message,id,reactions.limit('+reactionlimit+')},from,created_time,message,id,reactions.limit('+reactionlimit+')}&limit='+str(postlimit)+'&since='+startdate+'&until='+enddate)\n",
    "\n",
    "\n",
    "        except:\n",
    "            print('Problem with GRAPH GET. Lowering limit')\n",
    "            print('Limit was: '+str(postlimit))\n",
    "            postlimit=postlimit-10\n",
    "            print('Limit is now: '+str(postlimit))\n",
    "            try:\n",
    "                feed_data = graph.get_object(FB_ID+'/feed?fields=from,created_time,link,picture,message,story,scheduled_publish_time,reactions.limit('+reactionlimit+'){id,type},comments.limit('+commentlimit+'){comments.limit('+commentlimit+'){from,created_time,message,id,reactions.limit('+reactionlimit+')},from,created_time,message,id,reactions.limit('+reactionlimit+')}&limit='+str(postlimit)+'&since='+startdate+'&until='+enddate)\n",
    "            except:\n",
    "                print('Something went wrong, skipping '+FB_ID+'. ID was saved in '+missing)\n",
    "                x=x+1\n",
    "                skip_id(FB_ID)\n",
    "                continue\n",
    "        if not feed_data['data']:\n",
    "            print('Feed data empty. Skipping ID')\n",
    "            x=x+1\n",
    "            continue\n",
    "        else:\n",
    "            x=x+1\n",
    "        DATA = []\n",
    "\n",
    "        for post in feed_data['data']:\n",
    "            post_time = post['created_time']\n",
    "            post_id = post['id']\n",
    "            post_author = post['from']\n",
    "            print('PostID: '+ str(post_id)+' from '+post_time)\n",
    "            if 'message' in post:\n",
    "                post_message = post['message']\n",
    "            else:\n",
    "                post_message = ''\n",
    "            if 'picture' in post:\n",
    "                post_picture = post['picture']\n",
    "            else:\n",
    "                post_picture = ''\n",
    "            if 'link' in post:\n",
    "                post_link = post['link']\n",
    "            else:\n",
    "                post_link = ''\n",
    "\n",
    "            #iterate over post reactions\n",
    "            post_reactions = []\n",
    "            if 'reactions' in post:\n",
    "                reactions = post['reactions']\n",
    "                for reaction in reactions['data']:\n",
    "                    post_reactions.append(reaction)\n",
    "                paging_postreactions()\n",
    "\n",
    "            #iterate over comments\n",
    "            comments_data = []\n",
    "            if 'comments' in post:\n",
    "                comments = post['comments']\n",
    "                for comment in comments['data']: \n",
    "                    comment_time = comment['created_time']\n",
    "                    comment_id = comment['id']\n",
    "                    comment_author = comment['from']\n",
    "                    if 'message' in comment:\n",
    "                        comment_message = comment['message']\n",
    "                    else:\n",
    "                        comment_message = ''\n",
    "\n",
    "                    #iterate over comment reactions\n",
    "                    comment_reactions = []\n",
    "                    if 'reactions' in comment:\n",
    "                        reactions = comment['reactions']\n",
    "                        for reaction in reactions['data']:\n",
    "                            comment_reactions.append(reaction)\n",
    "                        paging_commentreactions()\n",
    "\n",
    "                    #iterate over comments on comments\n",
    "                    commentcomments_data = []\n",
    "                    if 'comments' in comment:\n",
    "                        commentcomments = comment['comments']\n",
    "                        for commentcomment in commentcomments['data']:\n",
    "                            commentcomment_time = commentcomment['created_time']\n",
    "                            commentcomment_id = commentcomment['id']\n",
    "                            commentcomment_author = commentcomment['from']\n",
    "                            if 'message' in commentcomment:\n",
    "                                commentcomment_message = commentcomment['message']\n",
    "                            else:\n",
    "                                commentcomment_message = ''\n",
    "\n",
    "                            #iteratae over commentcomment reactions\n",
    "                            commentcomment_reactions = []\n",
    "                            if 'reactions' in commentcomments:\n",
    "                                reactions = commentcomment['reactions']\n",
    "                                for reaction in reactions['data']:\n",
    "                                    commentcomment_reactions.append(reaction)\n",
    "                                paging_commentcommentreactions()\n",
    "\n",
    "                            COMMENTCOMMENTDIC = {'commentcomment_time':commentcomment_time,'commentcomment_id':commentcomment_id,'commentcomment_message':commentcomment_message,'commentcomment_author':commentcomment_author,'commentcomment_reactions':commentcomment_reactions}\n",
    "                            commentcomments_data.append(COMMENTCOMMENTDIC)\n",
    "                        paging_commentcomment()\n",
    "\n",
    "\n",
    "\n",
    "                    COMMENTDIC = {'comment_time':comment_time,'comment_id':comment_id,'comment_message':comment_message,'comment_author':comment_author,'comment_reactions':comment_reactions,'commentcomments':commentcomments_data}\n",
    "                    comments_data.append(COMMENTDIC)\n",
    "                paging_comment()\n",
    "            POSTDATA = {'post_id':post_id,'post_time':post_time,'post_message':post_message,'post_author':post_author,'post_picture':post_picture,'post_link':post_link,'post_reactions':post_reactions,'comments':comments_data}\n",
    "\n",
    "            DATA.append(POSTDATA)\n",
    "\n",
    "\n",
    "            post_count=post_count+1\n",
    "            print('Posts scraped '+str(post_count))\n",
    "\n",
    "        print(\"Finished first post page.\")\n",
    "        if 'next' in feed_data['paging']:\n",
    "            print('Paging posts for '+FB_ID)\n",
    "        connection_page=1\n",
    "\n",
    "\n",
    "        #########################POST PAGING############################\n",
    "        try:\n",
    "            while 'next' in feed_data['paging'] and connection_page:\n",
    "                post_paging_token = feed_data['paging']['next']\n",
    "                post_paging_token = post_paging_token.split('/')\n",
    "                post_paging_token = '/' + post_paging_token[4] + '/' + post_paging_token[5]\n",
    "                try: \n",
    "                    print('Fetching data')\n",
    "                    feed_data = graph.get_object(id=post_paging_token)\n",
    "\n",
    "                except:\n",
    "                    print('Problem with GRAPH GET. Lowering limit')\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        time.sleep(1)\n",
    "                        limit=postlimit-10\n",
    "                        print('Postlimit was: '+str(postlimit)+' is now: '+str(limit))\n",
    "                        post_paging_token = post_paging_token.split('&')\n",
    "                        new_post_paging_token=post_paging_token[0] + '&' + post_paging_token[1] + '&' + post_paging_token[2]+ '&' + post_paging_token[3]+ '&limit='+str(limit)+'&' + post_paging_token[5]            \n",
    "                        feed_data = graph.get_object(id=new_post_paging_token)\n",
    "\n",
    "                    except:    \n",
    "                        print('Still problems with GRAPH GET. Lowering limit again') \n",
    "                        try:\n",
    "                            time.sleep(1)\n",
    "                            limit_2=10\n",
    "                            print('Postlimit was: '+str(limit)+' is now: '+str(limit_2))\n",
    "                            post_paging_token = post_paging_token.split('&')\n",
    "                            new_post_paging_token=post_paging_token[0] + '&' + post_paging_token[1] + '&' + post_paging_token[2]+ '&' + post_paging_token[3]+ '&limit='+str(limit_2)+'&' + post_paging_token[5]\n",
    "                            feed_data = graph.get_object(id=new_post_paging_token)\n",
    "                        except:\n",
    "                            print('Could not get paging data. Stopping paging for '+FB_ID+'. ID was saved in missing.json.')\n",
    "                            skip_id(FB_ID)\n",
    "                            connection_page=0\n",
    "                            continue\n",
    "\n",
    "                for post in feed_data['data']:\n",
    "                    post_time = post['created_time']\n",
    "                    post_id = post['id']\n",
    "                    post_author = post['from']\n",
    "                    print('PostID: '+ str(post_id)+' from '+post_time)\n",
    "\n",
    "                    if 'message' in post:\n",
    "                        post_message = post['message']\n",
    "                    else:\n",
    "                        post_message = ''\n",
    "                    if 'picture' in post:\n",
    "                        post_picture = post['picture']\n",
    "                    else:\n",
    "                        post_picture = ''\n",
    "                    if 'link' in post:\n",
    "                        post_link = post['link']\n",
    "                    else:\n",
    "                        post_link = ''\n",
    "\n",
    "                    #iterate over post reactions\n",
    "                    post_reactions = []\n",
    "                    if 'reactions' in post:\n",
    "                        reactions = post['reactions']\n",
    "                        for reaction in reactions['data']:\n",
    "                            post_reactions.append(reaction)\n",
    "                        paging_postreactions()\n",
    "\n",
    "                    #iterate over comments\n",
    "                    comments_data = []\n",
    "                    if 'comments' in post:\n",
    "                        comments = post['comments']\n",
    "                        for comment in comments['data']: \n",
    "                            comment_time = comment['created_time']\n",
    "                            comment_id = comment['id']\n",
    "                            comment_author = comment['from']\n",
    "                            if 'message' in comment:\n",
    "                                comment_message = comment['message']\n",
    "                            else:\n",
    "                                comment_message = ''\n",
    "\n",
    "                            #iterate over comment reactions\n",
    "                            comment_reactions = []\n",
    "                            if 'reactions' in comment:\n",
    "                                reactions = comment['reactions']\n",
    "                                for reaction in reactions['data']:\n",
    "                                    comment_reactions.append(reaction)\n",
    "                                paging_commentreactions()\n",
    "\n",
    "                            #iterate over comments on comments\n",
    "                            commentcomments_data = []\n",
    "                            if 'comments' in comment:\n",
    "\n",
    "                                commentcomments = comment['comments']\n",
    "                                for commentcomment in commentcomments['data']:\n",
    "                                    commentcomment_time = commentcomment['created_time']\n",
    "                                    commentcomment_id = commentcomment['id']\n",
    "                                    commentcomment_author = commentcomment['from']\n",
    "                                    if 'message' in commentcomment:\n",
    "                                        commentcomment_message = commentcomment['message']\n",
    "                                    else:\n",
    "                                        commentcomment_message = ''\n",
    "\n",
    "                                    #iteratae over commentcomment reactions\n",
    "                                    commentcomment_reactions = []\n",
    "                                    if 'reactions' in commentcomments:\n",
    "                                        reactions = commentcomment['reactions']\n",
    "                                        for reaction in reactions['data']:\n",
    "                                            commentcomment_reactions.append(reaction)\n",
    "                                        paging_commentcommentreactions()\n",
    "\n",
    "                                    COMMENTCOMMENTDIC = {'commentcomment_time':commentcomment_time,'commentcomment_id':commentcomment_id,'commentcomment_message':commentcomment_message,'commentcomment_author':commentcomment_author,'commentcomment_reactions':commentcomment_reactions}\n",
    "                                    commentcomments_data.append(COMMENTCOMMENTDIC)\n",
    "                                paging_commentcomment()\n",
    "\n",
    "\n",
    "\n",
    "                            COMMENTDIC = {'comment_time':comment_time,'comment_id':comment_id,'comment_message':comment_message,'comment_author':comment_author,'comment_reactions':comment_reactions,'commentcomments':commentcomments_data}\n",
    "                            comments_data.append(COMMENTDIC)\n",
    "                        paging_comment()\n",
    "                    POSTDATA = {'post_id':post_id,'post_time':post_time,'post_message':post_message,'post_author':post_author,'post_picture':post_picture,'post_link':post_link,'post_reactions':post_reactions,'comments':comments_data}\n",
    "\n",
    "                    DATA.append(POSTDATA)    \n",
    "\n",
    "                    post_count=post_count+1\n",
    "                    print('Posts scraped '+str(post_count)) \n",
    "        except:\n",
    "            skip_id(FB_ID)\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(DATA, f)\n",
    "            continue\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(DATA, f)\n",
    "\n",
    "        end_time=time.time()\n",
    "        duration=end_time-start_time \n",
    "        now = time.strftime(\"%H:%M\", time.localtime(time.time()))\n",
    "        print(str(FB_ID)+' with '+str(post_count)+' posts scraped in: '+str(round(duration,2))+' seconds. Time is: '+str(now))\n",
    "\n",
    "    end_time_total=time.time()\n",
    "    duration_total=round(((end_time_total-start_time_total)/60),0)\n",
    "    now = time.strftime(\"%H:%M\", time.localtime(time.time()))\n",
    "\n",
    "    print('Scraping of '+seedlist+ ' ended at '+str(now)+' after '+str(duration_total)+' minutes')\n",
    "    if email_notifications:\n",
    "        for mail in mails:\n",
    "            send_mail(mail,\"Motherscraper finished \"+str(now), \"Motherscraper successfully finished scraping \"+seedlist+\" in \"+ str(duration_total)+\" minutes\")\n",
    "except Exception as e: \n",
    "    print('Problem in the script: '+str(e)+' \\nPlease edit the seedlist to start at '+str(FB_ID)+' and restart the script')\n",
    "    if email_notifications:\n",
    "        for mail in mails:\n",
    "            send_mail(mail,\"Motherscraper has unexpectedly stopped \"+str(now), \"Motherscraper scraping from \"+seedlist+\" has unexspectedly stopped at \"+str(FB_ID))\n",
    "\n",
    "print('Scraping done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
